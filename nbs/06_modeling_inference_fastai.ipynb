{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-trigger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:22.912907Z",
     "start_time": "2022-02-01T23:50:22.910447Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp modeling.inferencefastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "whole-poland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:25.802910Z",
     "start_time": "2022-02-01T23:50:23.182170Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from sklearn import datasets\n",
    "from sdsde.azure.filehandling import FileHandling\n",
    "from sdsde.snowflake.query import SnowflakeConnect\n",
    "from datetime import datetime as dt\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-institution",
   "metadata": {},
   "source": [
    "# Inference Functionality\n",
    "\n",
    "These functions are designed to help with anything in the Inference stage of the ML life cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charitable-certification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:27.001693Z",
     "start_time": "2022-02-01T23:50:25.805033Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "from sdsde.wrapper.azurewrapper import blob_puller\n",
    "from sdsde.modeling.inference import pull_sklearn_object_from_data_lake, push_dataframe_to_data_lake_as_parquet, move_parquet_table_to_snowflake\n",
    "from sdsde.modeling.preprocessingfastai import load_pandas\n",
    "from fastai.learner import load_learner\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-surprise",
   "metadata": {},
   "source": [
    "## Model Pulling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radical-vitamin",
   "metadata": {},
   "source": [
    "### `pull_fastai_learner_from_data_lake`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "talented-surface",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:27.054229Z",
     "start_time": "2022-02-01T23:50:27.048829Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def pull_fastai_learner_from_data_lake(file_name: str, path: str, container: str,\n",
    "                                       connection_str: str, overwrite: bool = True,\n",
    "                                       cpu: bool = True):\n",
    "    \"\"\"\n",
    "    Pulling save fastai tabular model from azure blob storage.\n",
    "\n",
    "    Args:\n",
    "    * file_name (str): Model Name/ File name\n",
    "    * path (str): Path location in azure blob and will be saved in the same location locally\n",
    "    * container (str): Container model is in\n",
    "    * connection_str (str): Connection String to Azure Storage\n",
    "    * overwrite (bool, optional): Overwrite model if locally exists. Defaults to True.\n",
    "    * cpu (bool, optional): CPU or False For GPU inference. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    * Tabular Learner: Model\n",
    "    \"\"\"\n",
    "    logger.info(f'loading learner object: {os.path.join(path, file_name)}')\n",
    "    blob_puller(files=[os.path.join(path, file_name)],\n",
    "                connection_str=connection_str,\n",
    "                container_name=container,\n",
    "                drop_location=path,\n",
    "                overwrite=overwrite)\n",
    "    learner = load_learner(os.path.join(path, file_name), cpu=cpu)\n",
    "    os.unlink(os.path.join(path, file_name))\n",
    "    logger.info('learner object loaded')\n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "promotional-cinema",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:27.264634Z",
     "start_time": "2022-02-01T23:50:27.249529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pull_fastai_learner_from_data_lake\" class=\"doc_header\"><code>pull_fastai_learner_from_data_lake</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>pull_fastai_learner_from_data_lake</code>(**`file_name`**:`str`, **`path`**:`str`, **`container`**:`str`, **`connection_str`**:`str`, **`overwrite`**:`bool`=*`True`*, **`cpu`**:`bool`=*`True`*)\n",
       "\n",
       "Pulling save fastai tabular model from azure blob storage.\n",
       "\n",
       "Args:\n",
       "* file_name (str): Model Name/ File name\n",
       "* path (str): Path location in azure blob and will be saved in the same location locally\n",
       "* container (str): Container model is in\n",
       "* connection_str (str): Connection String to Azure Storage\n",
       "* overwrite (bool, optional): Overwrite model if locally exists. Defaults to True.\n",
       "* cpu (bool, optional): CPU or False For GPU inference. Defaults to True.\n",
       "\n",
       "Returns:\n",
       "* Tabular Learner: Model"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pull_fastai_learner_from_data_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7cca4a",
   "metadata": {},
   "source": [
    "### ``pull_fastai_preprocess_from_data_lake``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e7a04e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:28.483142Z",
     "start_time": "2022-02-01T23:50:28.478529Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "\n",
    "def pull_fastai_preprocess_from_data_lake(file_name: str, path: str, container: str,\n",
    "                                          connection_str: str, overwrite: bool = True):\n",
    "    \"\"\"\n",
    "    Pull preprocess object to extraploate process onto a new training set.\n",
    "\n",
    "    ```\n",
    "    example:\n",
    "    dl_test = transformer.train.new(df_test)\n",
    "    dl_test.process()\n",
    "    X_test = dl_test.xs\n",
    "    y_test = dl_test.y\n",
    "    ```\n",
    "    Args:\n",
    "    * file_name (str): file name\n",
    "    * path (str): Path location in azure blob and will be saved in the same location locally\n",
    "    * container (str): Container model is in\n",
    "    * connection_str (str): Connection String to Azure Storage\n",
    "    * overwrite (bool, optional): Overwrite preprocess object if locally exists. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    * Tranformer: transformer to prepare new data set for model ingestion\n",
    "    \"\"\"\n",
    "    logger.info(f'loading preprocess object: {os.path.join(path, file_name)}')\n",
    "    blob_puller(files=[os.path.join(path, file_name)],\n",
    "                connection_str=connection_str,\n",
    "                container_name=container,\n",
    "                drop_location=path,\n",
    "                overwrite=overwrite)\n",
    "    transformer = load_pandas(os.path.join(path, file_name))\n",
    "    logger.info('preprocess object loaded')\n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b0c8299",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:28.870067Z",
     "start_time": "2022-02-01T23:50:28.854011Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pull_fastai_preprocess_from_data_lake\" class=\"doc_header\"><code>pull_fastai_preprocess_from_data_lake</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>pull_fastai_preprocess_from_data_lake</code>(**`file_name`**:`str`, **`path`**:`str`, **`container`**:`str`, **`connection_str`**:`str`, **`overwrite`**:`bool`=*`True`*)\n",
       "\n",
       "Pull preprocess object to extraploate process onto a new training set.\n",
       "\n",
       "```\n",
       "example:\n",
       "dl_test = transformer.train.new(df_test)\n",
       "dl_test.process()\n",
       "X_test = dl_test.xs\n",
       "y_test = dl_test.y\n",
       "```\n",
       "Args:\n",
       "* file_name (str): file name\n",
       "* path (str): Path location in azure blob and will be saved in the same location locally\n",
       "* container (str): Container model is in\n",
       "* connection_str (str): Connection String to Azure Storage\n",
       "* overwrite (bool, optional): Overwrite preprocess object if locally exists. Defaults to True.\n",
       "\n",
       "Returns:\n",
       "* Tranformer: transformer to prepare new data set for model ingestion"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pull_fastai_preprocess_from_data_lake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34de9619",
   "metadata": {},
   "source": [
    "### `pull_transform_predict_sklearn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5b33375",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:30.218339Z",
     "start_time": "2022-02-01T23:50:30.213942Z"
    }
   },
   "outputs": [],
   "source": [
    "# export \n",
    "\n",
    "\n",
    "def pull_transform_predict_sklearn(df, snowflake_connection, model_file_name: str,\n",
    "                                   model_file_path: str, container: str, connection_str: str,\n",
    "                                   transformer_path: str, transformer_name: str,\n",
    "                                   overwrite: bool = True, save_model: bool = True, model=None):\n",
    "    \"\"\"\n",
    "    predict on test set and send those predictions to azure data lake.\n",
    "\n",
    "    Args:\n",
    "    * model (sklearn model): Model Classifier\n",
    "    * snowflake_connection (sdsde function): Creation snowflake engine\n",
    "    * model_file_name (str): file name\n",
    "    * model_file_path (str): blob & local storage\n",
    "    * container (str): container name\n",
    "    * connection_str (str): Azure blob connection\n",
    "    * transformer_path (str): Blob location of tranformer for preprocessing\n",
    "    * transformer_name (str): name of transformer\n",
    "    * test_query (str): query to query for test\n",
    "    * overwrite (bool, optional): overwrite results. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "    * list: Test set, probabilities, predictions, model and transformer\n",
    "    \"\"\"\n",
    "    transformer = pull_fastai_preprocess_from_data_lake(file_name=transformer_name,\n",
    "                                                        path=transformer_path,\n",
    "                                                        container=container,\n",
    "                                                        connection_str=connection_str,\n",
    "                                                        overwrite=overwrite)\n",
    "    model = pull_sklearn_object_from_data_lake(file_name=model_file_name,\n",
    "                                               path=model_file_path,\n",
    "                                               container=container,\n",
    "                                               connection_str=connection_str)\n",
    "\n",
    "    dl_test = transformer.train.new(df)\n",
    "    dl_test.process()\n",
    "    X_test = dl_test.xs\n",
    "    y_test = dl_test.y\n",
    "    assert X_test.shape[0] == y_test.shape[0], 'y_test and x_test have different number of rows'\n",
    "    probs = model.predict_proba(X_test)\n",
    "    preds = model.predict(X_test)\n",
    "    return df, probs, preds, model, transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bc9c358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:30.413366Z",
     "start_time": "2022-02-01T23:50:30.403164Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"pull_transform_predict_sklearn\" class=\"doc_header\"><code>pull_transform_predict_sklearn</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>pull_transform_predict_sklearn</code>(**`df`**, **`snowflake_connection`**, **`model_file_name`**:`str`, **`model_file_path`**:`str`, **`container`**:`str`, **`connection_str`**:`str`, **`transformer_path`**:`str`, **`transformer_name`**:`str`, **`overwrite`**:`bool`=*`True`*, **`save_model`**:`bool`=*`True`*, **`model`**=*`None`*)\n",
       "\n",
       "predict on test set and send those predictions to azure data lake.\n",
       "\n",
       "Args:\n",
       "* model (sklearn model): Model Classifier\n",
       "* snowflake_connection (sdsde function): Creation snowflake engine\n",
       "* model_file_name (str): file name\n",
       "* model_file_path (str): blob & local storage\n",
       "* container (str): container name\n",
       "* connection_str (str): Azure blob connection\n",
       "* transformer_path (str): Blob location of tranformer for preprocessing\n",
       "* transformer_name (str): name of transformer\n",
       "* test_query (str): query to query for test\n",
       "* overwrite (bool, optional): overwrite results. Defaults to True.\n",
       "\n",
       "Returns:\n",
       "* list: Test set, probabilities, predictions, model and transformer"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(pull_transform_predict_sklearn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c1f88",
   "metadata": {},
   "source": [
    "### `push_prediction_to_dl_and_sf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bdbb86b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:31.702510Z",
     "start_time": "2022-02-01T23:50:31.696533Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def push_prediction_to_dl_and_sf(prediction_df: pd.DataFrame, snowflake_connection, df_col_types: dict,\n",
    "                                 prediction_path: str, sf_table_name: str, stage_name: str, stage_path: str,\n",
    "                                 pattern: str, replace_table: bool, container: str, connection_str: str,\n",
    "                                 overwrite: bool = True):\n",
    "    \"\"\"\n",
    "    A wrapper on a few sdsde functions that will push prediction in memory data set\n",
    "    to azure data lake and snowflake table.\n",
    "\n",
    "    Args:\n",
    "    * prediction_df (pd.DataFrame): Data Frame\n",
    "    * snowflake_connection (sdsde_function): Snowflake engine connection\n",
    "    * df_col_types (dict): col names and snowflake data types\n",
    "    * prediction_path (str): store predictions path\n",
    "    * sf_table_name (str): snowflake table name for predictions\n",
    "    * stage_name (str): Azure Data Lake Stage name\n",
    "    * stage_path (str): Stage Path\n",
    "    * pattern (str): pattern to read paritions\n",
    "    * replace_table (bool): True creates a new table False inserts to exisiting table\n",
    "    * container (str): container name\n",
    "    * connectin_str (str): Azure connection str\n",
    "    * overwrite (bool, optional): overwrite files. Defaults to True.\n",
    "    \"\"\"\n",
    "    push_dataframe_to_data_lake_as_parquet(prediction_df,\n",
    "                                           path=prediction_path,\n",
    "                                           container=container,\n",
    "                                           connection_str=connection_str,\n",
    "                                           overwrite=overwrite)\n",
    "    move_parquet_table_to_snowflake(sf_connection=snowflake_connection,\n",
    "                                    table_name=sf_table_name,\n",
    "                                    stage_name=stage_name,\n",
    "                                    path=stage_path,\n",
    "                                    columns_and_types=df_col_types,\n",
    "                                    pattern=pattern,\n",
    "                                    replace_table=replace_table)\n",
    "    logger.info(f'Preview {sf_table_name} {snowflake_connection.run_str_query(f\"SELECT * FROM {sf_table_name} LIMIT 10;\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9169e0f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:32.292122Z",
     "start_time": "2022-02-01T23:50:32.274799Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"push_prediction_to_dl_and_sf\" class=\"doc_header\"><code>push_prediction_to_dl_and_sf</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>push_prediction_to_dl_and_sf</code>(**`prediction_df`**:`DataFrame`, **`snowflake_connection`**, **`df_col_types`**:`dict`, **`prediction_path`**:`str`, **`sf_table_name`**:`str`, **`stage_name`**:`str`, **`stage_path`**:`str`, **`pattern`**:`str`, **`replace_table`**:`bool`, **`container`**:`str`, **`connection_str`**:`str`, **`overwrite`**:`bool`=*`True`*)\n",
       "\n",
       "A wrapper on a few sdsde functions that will push prediction in memory data set\n",
       "to azure data lake and snowflake table.\n",
       "\n",
       "Args:\n",
       "* prediction_df (pd.DataFrame): Data Frame\n",
       "* snowflake_connection (sdsde_function): Snowflake engine connection\n",
       "* df_col_types (dict): col names and snowflake data types\n",
       "* prediction_path (str): store predictions path\n",
       "* sf_table_name (str): snowflake table name for predictions\n",
       "* stage_name (str): Azure Data Lake Stage name\n",
       "* stage_path (str): Stage Path\n",
       "* pattern (str): pattern to read paritions\n",
       "* replace_table (bool): True creates a new table False inserts to exisiting table\n",
       "* container (str): container name\n",
       "* connectin_str (str): Azure connection str\n",
       "* overwrite (bool, optional): overwrite files. Defaults to True."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(push_prediction_to_dl_and_sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-kentucky",
   "metadata": {},
   "source": [
    "# Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "educated-despite",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:50:35.487486Z",
     "start_time": "2022-02-01T23:50:34.595923Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_azure.ipynb.\n",
      "Converted 02_utils_dataframes.ipynb.\n",
      "Converted 02_utils_parseyaml.ipynb.\n",
      "Converted 02_utils_stfp.ipynb.\n",
      "Converted 02_utils_traininghelpers.ipynb.\n",
      "Converted 02_utils_traininghelpers_fastai.ipynb.\n",
      "Converted 03_dstools_preparedata.ipynb.\n",
      "Converted 04_snowflake_copyinto.ipynb.\n",
      "Converted 04_snowflake_copyinto2.ipynb.\n",
      "Converted 04_snowflake_query.ipynb.\n",
      "Converted 05_azure_wrappers.ipynb.\n",
      "Converted 06_modeling_inference.ipynb.\n",
      "Converted 06_modeling_inference_fastai.ipynb.\n",
      "Converted 06_modeling_premodel.ipynb.\n",
      "Converted 06_modeling_preprocessing.ipynb.\n",
      "Converted 06_modeling_preprocessing_fastai.ipynb.\n",
      "Converted 06_modeling_training.ipynb.\n",
      "Converted 06_modeling_training_fastai.ipynb.\n",
      "Converted 07_Binary_Classification_Fastai_Example_Notebook.ipynb.\n",
      "Converted 08_yaml_ingestion_binary_classification.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
