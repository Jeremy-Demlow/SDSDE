{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "technical-trigger",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:39.843356Z",
     "start_time": "2022-02-01T23:57:39.841459Z"
    }
   },
   "outputs": [],
   "source": [
    "#default_exp modeling.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "whole-poland",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:41.821454Z",
     "start_time": "2022-02-01T23:57:40.341407Z"
    }
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reduced-institution",
   "metadata": {},
   "source": [
    "# Training Functionality\n",
    "\n",
    "These functions are designed to help with anything in the training stage of the ML life cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "charitable-certification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:43.909721Z",
     "start_time": "2022-02-01T23:57:41.963679Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "import xgboost\n",
    "import os\n",
    "import pickle\n",
    "import logging\n",
    "\n",
    "from hyperopt import fmin, tpe, STATUS_OK, Trials, hp, space_eval\n",
    "from sdsde.wrapper.azurewrapper import blob_pusher\n",
    "from sklearn import metrics\n",
    "from fastai.basics import *\n",
    "from fastai.tabular.all import *\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-surprise",
   "metadata": {},
   "source": [
    "## Hypertuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-google",
   "metadata": {},
   "source": [
    "### `HpOptMultilabel`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "vulnerable-understanding",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:43.920380Z",
     "start_time": "2022-02-01T23:57:43.911160Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class HpOptMultilabel:\n",
    "    \"\"\"Class that hypertunes an arbitrary model to multilabel classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, parameter_space=None, model=xgboost.XGBClassifier):\n",
    "        \"\"\"Initialization takes in a test and train set and an optional hyperparameter space\n",
    "\n",
    "        Args:\n",
    "        * X_train (array): training features\n",
    "        * X_test (array): testing features\n",
    "        * y_train (array): testing labels\n",
    "        * y_test (array): testing labels\n",
    "        * parameter_space (dict): hyperopt compatible parameter space\n",
    "        * model (module pointer): machine learning model compatiable with parameter space\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "\n",
    "        if parameter_space is None:\n",
    "            self.parameter_space = {\n",
    "                'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                'reg_alpha': hp.uniform('reg_alpha', 0, 5),\n",
    "                'reg_lambda': hp.uniform('reg_lambda', 0, 5),\n",
    "                'min_child_weight': hp.uniform('min_child_weight', 0, 5),\n",
    "                'gamma': hp.uniform('gamma', 0, 5),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                'tree_method': hp.choice('tree_method', ['hist', 'exact', 'approx']),\n",
    "                'objective': hp.choice('objective', ['multi:softmax', 'multi:softprob']),\n",
    "                'eval_metric': hp.choice('eval_metric', ['mlogloss', 'merror']),\n",
    "                'gpu_id': hp.choice('gpu_id', [0]),\n",
    "                'use_label_encoder': hp.choice('use_label_encoder', [False]),\n",
    "            }\n",
    "        else:\n",
    "            self.parameter_space = parameter_space\n",
    "\n",
    "    def objective(self, params):\n",
    "        \"\"\"Objective function for loss that is provided to perform the MINLP\n",
    "        optimizaiton in hyperopt\n",
    "\n",
    "        Args:\n",
    "        * params (dict): hyperopt formated dictionary of hyperparameters\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        model = self.model(**params)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        pred_proba = model.predict_proba(self.X_test)\n",
    "        loss = 1 - metrics.roc_auc_score(self.y_test, pred_proba, multi_class='ovr', average='macro')\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self, max_evals=20):\n",
    "        \"\"\"optimizes the hyperparameter space in the object\n",
    "\n",
    "        Args:\n",
    "        * max_evals: number of hyperopt iterations\n",
    "\n",
    "        Returns:\n",
    "        * dict: best hyperparameters\n",
    "        \"\"\"\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=self.objective,\n",
    "                    space=self.parameter_space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    trials=trials)\n",
    "        return space_eval(self.parameter_space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "incorporate-bailey",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:43.935041Z",
     "start_time": "2022-02-01T23:57:43.922250Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HpOptMultilabel\" class=\"doc_header\"><code>class</code> <code>HpOptMultilabel</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HpOptMultilabel</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBClassifier`*)\n",
       "\n",
       "Class that hypertunes an arbitrary model to multilabel classification\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptMultilabel.__init__\" class=\"doc_header\"><code>HpOptMultilabel.__init__</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptMultilabel.__init__</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBClassifier`*)\n",
       "\n",
       "Initialization takes in a test and train set and an optional hyperparameter space\n",
       "\n",
       "Args:\n",
       "* X_train (array): training features\n",
       "* X_test (array): testing features\n",
       "* y_train (array): testing labels\n",
       "* y_test (array): testing labels\n",
       "* parameter_space (dict): hyperopt compatible parameter space\n",
       "* model (module pointer): machine learning model compatiable with parameter space"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptMultilabel.objective\" class=\"doc_header\"><code>HpOptMultilabel.objective</code><a href=\"__main__.py#L44\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptMultilabel.objective</code>(**`params`**)\n",
       "\n",
       "Objective function for loss that is provided to perform the MINLP\n",
       "optimizaiton in hyperopt\n",
       "\n",
       "Args:\n",
       "* params (dict): hyperopt formated dictionary of hyperparameters\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptMultilabel.optimize\" class=\"doc_header\"><code>HpOptMultilabel.optimize</code><a href=\"__main__.py#L60\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptMultilabel.optimize</code>(**`max_evals`**=*`20`*)\n",
       "\n",
       "optimizes the hyperparameter space in the object\n",
       "\n",
       "Args:\n",
       "* max_evals: number of hyperopt iterations\n",
       "\n",
       "Returns:\n",
       "* dict: best hyperparameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HpOptMultilabel)\n",
    "show_doc(HpOptMultilabel.__init__)\n",
    "show_doc(HpOptMultilabel.objective)\n",
    "show_doc(HpOptMultilabel.optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-territory",
   "metadata": {},
   "source": [
    "Example of passing in a custom parameter set to an XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "extreme-czech",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:54.900339Z",
     "start_time": "2022-02-01T23:57:46.433658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002774 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▋                        | 1/10 [00:00<00:04,  2.16trial/s, best loss: 0.0270531400966183]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003591 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.027053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████                    | 2/10 [00:00<00:03,  2.34trial/s, best loss: 0.022222222222222143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002915 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 0.022222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████▌                 | 3/10 [00:03<00:11,  1.62s/trial, best loss: 0.022222222222222143]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002641 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 0.022222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████               | 4/10 [00:04<00:07,  1.21s/trial, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.063942 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████▌            | 5/10 [00:05<00:05,  1.06s/trial, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002873 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████          | 6/10 [00:05<00:03,  1.12trial/s, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003395 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████▌       | 7/10 [00:06<00:02,  1.19trial/s, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002627 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████     | 8/10 [00:07<00:01,  1.33trial/s, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002477 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████▌  | 9/10 [00:07<00:00,  1.55trial/s, best loss: 0.009661835748792313]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003147 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 0.009662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 10/10 [00:07<00:00,  1.25trial/s, best loss: 0.009661835748792313]\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.9400000000000001,\n",
      "              enable_categorical=False, eval_metric='mlogloss',\n",
      "              gamma=1.2432948057293043, gpu_id=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.18219904135916973,\n",
      "              max_delta_step=None, max_depth=15, min_child_weight=None,\n",
      "              missing=nan, monotone_constraints=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, objective='multi:softprob',\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None,\n",
      "              subsample=0.7000000000000001, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None, ...)\n",
      "AUC: 0.9903381642512077\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_iris()\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                    'gamma': hp.uniform('gamma', 0, 5),\n",
    "                    'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                    'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                    'objective': hp.choice('objective', ['multi:softmax', 'multi:softprob']),\n",
    "                    'eval_metric': hp.choice('eval_metric', ['mlogloss', 'merror']),\n",
    "                    'use_label_encoder': hp.choice('use_label_encoder', [False])\n",
    "                   }\n",
    "\n",
    "opt = HpOptMultilabel(X_train, X_test, y_train, y_test, parameter_space=parameter_space)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = xgboost.XGBClassifier(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test, pred_proba, multi_class='ovr', average='macro')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abstract-residence",
   "metadata": {},
   "source": [
    "Example of passing in a custom set of parameters to a random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "charged-contribution",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:56.006853Z",
     "start_time": "2022-02-01T23:57:54.901956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.001163 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▌                       | 1/10 [00:00<00:00,  9.33trial/s, best loss: 0.01207729468599028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000951 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.012077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████▏                    | 2/10 [00:00<00:00,  9.32trial/s, best loss: 0.01207729468599028]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000819 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 0.012077\n",
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000818 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 0.012077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████               | 4/10 [00:00<00:00,  9.98trial/s, best loss: 0.007729468599033784]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000851 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 0.007729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████▌            | 5/10 [00:00<00:00,  9.72trial/s, best loss: 0.007729468599033784]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000816 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 0.007729\n",
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000952 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 0.007729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████▌       | 7/10 [00:00<00:00, 10.05trial/s, best loss: 0.005797101449275366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000877 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 0.005797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████     | 8/10 [00:00<00:00,  9.96trial/s, best loss: 0.005797101449275366]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000815 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 0.005797\n",
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000807 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 0.005797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 10/10 [00:01<00:00,  9.99trial/s, best loss: 0.005797101449275366]\n",
      "RandomForestClassifier(max_depth=12)\n",
      "AUC: 0.9898550724637681\n"
     ]
    }
   ],
   "source": [
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                   }\n",
    "\n",
    "opt = HpOptMultilabel(X_train, X_test, y_train, y_test, parameter_space=parameter_space, model=RandomForestClassifier)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = RandomForestClassifier(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test, pred_proba, multi_class='ovr', average='macro')\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-christopher",
   "metadata": {},
   "source": [
    "### `HpOptBinary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "sacred-variation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:56.015668Z",
     "start_time": "2022-02-01T23:57:56.008430Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class HpOptBinary:\n",
    "    \"\"\"Class that hypertunes an arbitrary model to binary classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, parameter_space=None, model=xgboost.XGBClassifier):\n",
    "        \"\"\"Initialization takes in a test and train set and an optional hyperparameter space\n",
    "\n",
    "        Args:\n",
    "        * X_train (array): training features\n",
    "        * X_test (array): testing features\n",
    "        * y_train (array): testing labels\n",
    "        * y_test (array): testing labels\n",
    "        * parameter_space (dict): hyperopt compatible parameter space\n",
    "        * model (module pointer): machine learning model compatiable with parameter space\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "\n",
    "        if parameter_space is None:\n",
    "            self.parameter_space = {\n",
    "                'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                'reg_alpha': hp.uniform('reg_alpha', 0, 5),\n",
    "                'reg_lambda': hp.uniform('reg_lambda', 0, 5),\n",
    "                'min_child_weight': hp.uniform('min_child_weight', 0, 5),\n",
    "                'gamma': hp.uniform('gamma', 0, 5),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                'tree_method': hp.choice('tree_method', ['hist', 'exact', 'approx']),\n",
    "                'objective': hp.choice('objective', ['binary:logistic', 'binary:logitraw', 'binary:hinge']),\n",
    "                'eval_metric': hp.choice('eval_metric', ['logloss', 'error', 'auc', 'aucpr', 'map']),\n",
    "                'gpu_id': hp.choice('gpu_id', [0]),\n",
    "                'use_label_encoder': hp.choice('use_label_encoder', [False]),\n",
    "            }\n",
    "        else:\n",
    "            self.parameter_space = parameter_space\n",
    "\n",
    "    def objective(self, params):\n",
    "        \"\"\"Objective function for loss that is provided to perform the MINLP\n",
    "        optimizaiton in hyperopt\n",
    "\n",
    "        Args:\n",
    "        * params (dict): hyperopt formated dictionary of hyperparameters\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        model = self.model(**params)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        pred_proba = model.predict_proba(self.X_test)\n",
    "        loss = 1 - metrics.roc_auc_score(self.y_test, pred_proba[:, 1])\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self, max_evals=20):\n",
    "        \"\"\"optimizes the hyperparameter space in the object\n",
    "\n",
    "        Args:\n",
    "        * max_evals: number of hyperopt iterations\n",
    "\n",
    "        Returns:\n",
    "        * dict: best hyperparameters\n",
    "        \"\"\"\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=self.objective,\n",
    "                    space=self.parameter_space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    trials=trials)\n",
    "        return space_eval(self.parameter_space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "medium-oasis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:57:56.029194Z",
     "start_time": "2022-02-01T23:57:56.017792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HpOptBinary\" class=\"doc_header\"><code>class</code> <code>HpOptBinary</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HpOptBinary</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBClassifier`*)\n",
       "\n",
       "Class that hypertunes an arbitrary model to binary classification\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptBinary.__init__\" class=\"doc_header\"><code>HpOptBinary.__init__</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptBinary.__init__</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBClassifier`*)\n",
       "\n",
       "Initialization takes in a test and train set and an optional hyperparameter space\n",
       "\n",
       "Args:\n",
       "* X_train (array): training features\n",
       "* X_test (array): testing features\n",
       "* y_train (array): testing labels\n",
       "* y_test (array): testing labels\n",
       "* parameter_space (dict): hyperopt compatible parameter space\n",
       "* model (module pointer): machine learning model compatiable with parameter space"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptBinary.objective\" class=\"doc_header\"><code>HpOptBinary.objective</code><a href=\"__main__.py#L44\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptBinary.objective</code>(**`params`**)\n",
       "\n",
       "Objective function for loss that is provided to perform the MINLP\n",
       "optimizaiton in hyperopt\n",
       "\n",
       "Args:\n",
       "* params (dict): hyperopt formated dictionary of hyperparameters\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptBinary.optimize\" class=\"doc_header\"><code>HpOptBinary.optimize</code><a href=\"__main__.py#L60\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptBinary.optimize</code>(**`max_evals`**=*`20`*)\n",
       "\n",
       "optimizes the hyperparameter space in the object\n",
       "\n",
       "Args:\n",
       "* max_evals: number of hyperopt iterations\n",
       "\n",
       "Returns:\n",
       "* dict: best hyperparameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HpOptBinary)\n",
    "show_doc(HpOptBinary.__init__)\n",
    "show_doc(HpOptBinary.objective)\n",
    "show_doc(HpOptBinary.optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-manhattan",
   "metadata": {},
   "source": [
    "Example of passing in a custom parameter set to an XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "quick-multiple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:04.007475Z",
     "start_time": "2022-02-01T23:57:56.031586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002559 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▌                       | 1/10 [00:00<00:03,  2.33trial/s, best loss: 0.01552323056882321]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002964 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.015523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████                    | 2/10 [00:01<00:04,  1.66trial/s, best loss: 0.005644811115935733]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003888 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 0.005645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████▌                 | 3/10 [00:01<00:03,  1.85trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002863 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████               | 4/10 [00:02<00:02,  2.04trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003050 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████▌            | 5/10 [00:02<00:02,  2.12trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003161 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████          | 6/10 [00:03<00:02,  1.53trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003774 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████▌       | 7/10 [00:04<00:02,  1.32trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002774 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████     | 8/10 [00:04<00:01,  1.50trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002884 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████▌  | 9/10 [00:05<00:00,  1.78trial/s, best loss: 0.001085540599218393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003308 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 0.001086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████| 10/10 [00:05<00:00,  1.76trial/s, best loss: 0.001085540599218393]\n",
      "XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=0.68,\n",
      "              enable_categorical=False, eval_metric='error',\n",
      "              gamma=0.01197826414525871, gpu_id=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.06734041838405497,\n",
      "              max_delta_step=None, max_depth=20, min_child_weight=None,\n",
      "              missing=nan, monotone_constraints=None, n_estimators=100,\n",
      "              n_jobs=None, num_parallel_tree=None, objective='binary:logitraw',\n",
      "              predictor=None, random_state=None, reg_alpha=None,\n",
      "              reg_lambda=None, scale_pos_weight=None, subsample=0.55,\n",
      "              tree_method=None, use_label_encoder=False,\n",
      "              validate_parameters=None, ...)\n",
      "AUC: 0.9989144594007816\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_breast_cancer()\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                    'gamma': hp.uniform('gamma', 0, 5),\n",
    "                    'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                    'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                    'objective': hp.choice('objective', ['binary:logistic', 'binary:logitraw', 'binary:hinge']),\n",
    "                    'eval_metric': hp.choice('eval_metric', ['logloss', 'error', 'auc', 'aucpr', 'map']),\n",
    "                    'use_label_encoder': hp.choice('use_label_encoder', [False])\n",
    "                   }\n",
    "\n",
    "opt = HpOptBinary(X_train, X_test, y_train, y_test, parameter_space=parameter_space)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = xgboost.XGBClassifier(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "voluntary-decrease",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:05.570541Z",
     "start_time": "2022-02-01T23:58:04.009026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.001014 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▌                      | 1/10 [00:00<00:01,  6.73trial/s, best loss: 0.003752535496957532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000902 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.003753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████                    | 2/10 [00:00<00:01,  7.34trial/s, best loss: 0.003752535496957532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000851 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 0.003753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████▌                 | 3/10 [00:00<00:00,  7.21trial/s, best loss: 0.003752535496957532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000872 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 0.003753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████               | 4/10 [00:00<00:00,  7.24trial/s, best loss: 0.003752535496957532]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000787 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 0.003753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████            | 5/10 [00:00<00:00,  7.18trial/s, best loss: 0.0034482758620689724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000821 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|██████████████▍         | 6/10 [00:00<00:00,  7.00trial/s, best loss: 0.0034482758620689724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000946 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████▊       | 7/10 [00:00<00:00,  7.04trial/s, best loss: 0.0034482758620689724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000826 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████▏    | 8/10 [00:01<00:00,  7.06trial/s, best loss: 0.0034482758620689724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000828 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████▌  | 9/10 [00:01<00:00,  7.14trial/s, best loss: 0.0034482758620689724]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000816 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 0.003448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:01<00:00,  7.12trial/s, best loss: 0.0034482758620688614]\n",
      "RandomForestClassifier(max_depth=11)\n",
      "AUC: 0.9962474645030426\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_breast_cancer()\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                   }\n",
    "\n",
    "opt = HpOptBinary(X_train, X_test, y_train, y_test, parameter_space=parameter_space, model=RandomForestClassifier)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = RandomForestClassifier(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred_proba = model.predict_proba(X_test)\n",
    "auc = metrics.roc_auc_score(y_test, pred_proba[:, 1])\n",
    "print(f'AUC: {auc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-cigarette",
   "metadata": {},
   "source": [
    "### `HpOptRegression`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "average-queens",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:05.579699Z",
     "start_time": "2022-02-01T23:58:05.571892Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class HpOptRegression:\n",
    "    \"\"\"Class that hypertunes an arbitrary model to regression classification\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, parameter_space=None, model=xgboost.XGBRegressor):\n",
    "        \"\"\"Initialization takes in a test and train set and an optional hyperparameter space\n",
    "\n",
    "        Args:\n",
    "        * X_train (array): training features\n",
    "        * X_test (array): testing features\n",
    "        * y_train (array): testing labels\n",
    "        * y_test (array): testing labels\n",
    "        * parameter_space (dict): hyperopt compatible parameter space\n",
    "        * model (module pointer): machine learning model compatiable with parameter space\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.model = model\n",
    "\n",
    "        if parameter_space is None:\n",
    "            self.parameter_space = {\n",
    "                'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                'reg_alpha': hp.uniform('reg_alpha', 0, 5),\n",
    "                'reg_lambda': hp.uniform('reg_lambda', 0, 5),\n",
    "                'min_child_weight': hp.uniform('min_child_weight', 0, 5),\n",
    "                'gamma': hp.uniform('gamma', 0, 5),\n",
    "                'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                'tree_method': hp.choice('tree_method', ['hist', 'exact', 'approx']),\n",
    "                'objective': hp.choice('objective', ['reg:squarederror', 'reg:squaredlogerror']),\n",
    "                'eval_metric': hp.choice('eval_metric', ['rmse', 'mae', 'mape', 'rmsle']),\n",
    "                'gpu_id': hp.choice('gpu_id', [0]),\n",
    "            }\n",
    "        else:\n",
    "            self.parameter_space = parameter_space\n",
    "\n",
    "    def objective(self, params):\n",
    "        \"\"\"Objective function for loss that is provided to perform the MINLP\n",
    "        optimizaiton in hyperopt\n",
    "\n",
    "        Args:\n",
    "        * params (dict): hyperopt formated dictionary of hyperparameters\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        model = self.model(**params)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        loss = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self, max_evals=20):\n",
    "        \"\"\"optimizes the hyperparameter space in the object\n",
    "\n",
    "        Args:\n",
    "        * max_evals: number of hyperopt iterations\n",
    "\n",
    "        Returns:\n",
    "        * dict: best hyperparameters\n",
    "        \"\"\"\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=self.objective,\n",
    "                    space=self.parameter_space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=max_evals,\n",
    "                    trials=trials)\n",
    "        return space_eval(self.parameter_space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "regulated-resistance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:05.590680Z",
     "start_time": "2022-02-01T23:58:05.581319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HpOptRegression\" class=\"doc_header\"><code>class</code> <code>HpOptRegression</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HpOptRegression</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBRegressor`*)\n",
       "\n",
       "Class that hypertunes an arbitrary model to regression classification\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptRegression.__init__\" class=\"doc_header\"><code>HpOptRegression.__init__</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptRegression.__init__</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`parameter_space`**=*`None`*, **`model`**=*`XGBRegressor`*)\n",
       "\n",
       "Initialization takes in a test and train set and an optional hyperparameter space\n",
       "\n",
       "Args:\n",
       "* X_train (array): training features\n",
       "* X_test (array): testing features\n",
       "* y_train (array): testing labels\n",
       "* y_test (array): testing labels\n",
       "* parameter_space (dict): hyperopt compatible parameter space\n",
       "* model (module pointer): machine learning model compatiable with parameter space"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptRegression.objective\" class=\"doc_header\"><code>HpOptRegression.objective</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptRegression.objective</code>(**`params`**)\n",
       "\n",
       "Objective function for loss that is provided to perform the MINLP\n",
       "optimizaiton in hyperopt\n",
       "\n",
       "Args:\n",
       "* params (dict): hyperopt formated dictionary of hyperparameters\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptRegression.optimize\" class=\"doc_header\"><code>HpOptRegression.optimize</code><a href=\"__main__.py#L59\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptRegression.optimize</code>(**`max_evals`**=*`20`*)\n",
       "\n",
       "optimizes the hyperparameter space in the object\n",
       "\n",
       "Args:\n",
       "* max_evals: number of hyperopt iterations\n",
       "\n",
       "Returns:\n",
       "* dict: best hyperparameters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HpOptRegression)\n",
    "show_doc(HpOptRegression.__init__)\n",
    "show_doc(HpOptRegression.objective)\n",
    "show_doc(HpOptRegression.optimize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-summary",
   "metadata": {},
   "source": [
    "Example of passing in a custom parameter set to an XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "enormous-swing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:43.837454Z",
     "start_time": "2022-02-01T23:58:05.592032Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdemlow/miniconda3/envs/dsde_tester_only/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.002051 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▊                         | 1/10 [00:00<00:03,  2.42trial/s, best loss: 382.1420797347393]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003195 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 382.142080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████▌                      | 2/10 [00:00<00:03,  2.24trial/s, best loss: 83.14360105909299]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003565 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 83.143601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████▍                   | 3/10 [00:02<00:05,  1.25trial/s, best loss: 22.26331950990619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.004754 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 22.263320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████▏                | 4/10 [00:02<00:04,  1.50trial/s, best loss: 22.26331950990619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.007802 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 22.263320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|██████████████              | 5/10 [00:02<00:02,  1.73trial/s, best loss: 22.26331950990619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003551 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 22.263320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████▊           | 6/10 [00:21<00:27,  6.80s/trial, best loss: 22.26331950990619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003100 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 22.263320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████▌        | 7/10 [00:29<00:21,  7.21s/trial, best loss: 22.26331950990619]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.005583 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 22.263320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████▌     | 8/10 [00:34<00:12,  6.36s/trial, best loss: 14.797843019213886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003923 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 14.797843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████▎  | 9/10 [00:35<00:04,  4.61s/trial, best loss: 14.797843019213886]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.004712 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 14.797843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 10/10 [00:37<00:00,  3.75s/trial, best loss: 7.480335479601239]\n",
      "XGBRegressor(base_score=None, booster=None, colsample_bylevel=None,\n",
      "             colsample_bynode=None, colsample_bytree=0.34,\n",
      "             enable_categorical=False, eval_metric='mae',\n",
      "             gamma=1.9238588058422383, gpu_id=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=0.08056615747341234,\n",
      "             max_delta_step=None, max_depth=19, min_child_weight=None,\n",
      "             missing=nan, monotone_constraints=None, n_estimators=100,\n",
      "             n_jobs=None, num_parallel_tree=None, predictor=None,\n",
      "             random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "             scale_pos_weight=None, subsample=0.75, tree_method=None,\n",
      "             use_label_encoder=False, validate_parameters=None, verbosity=None)\n",
      "RMSE: 2.7350201972931094\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_boston()\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                    'gamma': hp.uniform('gamma', 0, 5),\n",
    "                    'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                    'colsample_bytree': hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                    'objective': hp.choice('objective', ['reg:squarederror', 'reg:squaredlogerror',]),\n",
    "                    'eval_metric': hp.choice('eval_metric', ['rmse', 'mae', 'mape', 'rmsle']),\n",
    "                    'use_label_encoder': hp.choice('use_label_encoder', [False])\n",
    "                   }\n",
    "\n",
    "opt = HpOptRegression(X_train, X_test, y_train, y_test, parameter_space=parameter_space)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = xgboost.XGBRegressor(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(f'RMSE: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "worst-edward",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:45.919650Z",
     "start_time": "2022-02-01T23:58:43.844761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jdemlow/miniconda3/envs/dsde_tester_only/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n",
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000952 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▋                        | 1/10 [00:00<00:01,  4.55trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000835 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████▍                     | 2/10 [00:00<00:01,  5.02trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.001177 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████                   | 3/10 [00:00<00:01,  5.52trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000838 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████▊                | 4/10 [00:00<00:00,  6.24trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000847 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████▌             | 5/10 [00:00<00:00,  6.32trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000809 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████▏          | 6/10 [00:01<00:00,  5.98trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.003137 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|██████████████████▉        | 7/10 [00:01<00:00,  5.32trial/s, best loss: 10.652023839411436]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.000967 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 10.652024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|█████████████████████▌     | 8/10 [00:01<00:00,  5.43trial/s, best loss: 10.366898348544648]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.001141 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 10.366898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|█████████████████████████▏  | 9/10 [00:01<00:00,  5.13trial/s, best loss: 9.564085201909078]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.001695 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 9.564085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████| 10/10 [00:01<00:00,  5.49trial/s, best loss: 9.564085201909078]\n",
      "RandomForestRegressor(max_depth=13)\n",
      "RMSE: 3.3667505227667256\n"
     ]
    }
   ],
   "source": [
    "df = datasets.load_boston()\n",
    "X = df['data']\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "parameter_space = {\n",
    "                    'max_depth': hp.choice('max_depth', np.arange(21, dtype=int) + 2),\n",
    "                   }\n",
    "\n",
    "opt = HpOptRegression(X_train, X_test, y_train, y_test, parameter_space=parameter_space, model=RandomForestRegressor)\n",
    "best = opt.optimize(max_evals=10)\n",
    "model = RandomForestRegressor(**best)\n",
    "print(model)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "mse = np.sqrt(metrics.mean_squared_error(y_test, pred))\n",
    "print(f'RMSE: {mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corresponding-warrior",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-chassis",
   "metadata": {},
   "source": [
    "### `HpOptFeatureSelection`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "round-mills",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:45.930588Z",
     "start_time": "2022-02-01T23:58:45.921113Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "class HpOptFeatureSelection:\n",
    "    \"\"\"Uses hyperopt to remove features while maximizing an objective for a given problem\n",
    "    \"\"\"\n",
    "    def __init__(self, X_train, X_test, y_train, y_test, space, model, problem_type):\n",
    "        \"\"\"Initialize data, model, and problem type\n",
    "\n",
    "        Args:\n",
    "        * X_train (DataFrame): training dataframe of features\n",
    "        * X_test (DataFrame): testing dataframe of labels\n",
    "        * y_train (DataFrame): training dataframe of features\n",
    "        * y_test (DataFrame): testing dataframe of labels\n",
    "        * space (dict): dictionary with each feature corresponding to a hyperopt choice object\n",
    "        * model (object): model with \"fit\" and \"predict\" functions that are callable\n",
    "        * problem_type (str): one of \"binary\", \"regression\", or \"multilabel\"\n",
    "        \"\"\"\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.parameter_space = space\n",
    "        self.model = model\n",
    "        self.problem_type = problem_type\n",
    "\n",
    "    def objective_binary(self, params):\n",
    "        \"\"\"binary loss objective that grabs the columns for feature selection. uses AUC metric\n",
    "\n",
    "        Args:\n",
    "        * params (dict): which columns to use as features\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        cols = [i for i, j in params.items() if j == 1]\n",
    "        self.model.fit(self.X_train[cols], self.y_train)\n",
    "        pred_proba = self.model.predict_proba(self.X_test[cols])\n",
    "        loss = 1 - metrics.roc_auc_score(self.y_test, pred_proba[:, 1])\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def objective_multi(self, params):\n",
    "        \"\"\"multilabel loss objective that grabs the columns for feature selection. uses AUC metric\n",
    "\n",
    "        Args:\n",
    "        * params (dict): which columns to use as features\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        model = self.model(**params)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        pred_proba = model.predict_proba(self.X_test)\n",
    "        loss = 1 - metrics.roc_auc_score(self.y_test, pred_proba, multi_class='ovr', average='macro')\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def objective_regression(self, params):\n",
    "        \"\"\"regression loss objective that grabs the columns for feature selection. uses MSE metric\n",
    "\n",
    "        Args:\n",
    "        * params (dict): which columns to use as features\n",
    "\n",
    "        Returns:\n",
    "        * dict: loss and status for hyperopt optimization\n",
    "        \"\"\"\n",
    "        model = self.model(**params)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_pred = model.predict(self.X_test)\n",
    "        loss = metrics.mean_squared_error(self.y_test, y_pred)\n",
    "        return {'loss': loss, 'status': STATUS_OK}\n",
    "\n",
    "    def optimize(self, max_evals=20):\n",
    "        \"\"\"optimizes a feature space for each type of problem\n",
    "\n",
    "        Args:\n",
    "        * max_evals (int, optional): number of hyperopt evaluations. Defaults to 20.\n",
    "\n",
    "        Returns:\n",
    "        * object: hyperopt optimized object of parameters which are features\n",
    "        \"\"\"\n",
    "        trials = Trials()\n",
    "        if self.problem_type == 'binary':\n",
    "            best = fmin(fn=self.objective_binary,\n",
    "                        space=self.parameter_space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=max_evals,\n",
    "                        trials=trials)\n",
    "        elif self.problem_type == 'multilabel':\n",
    "            best = fmin(fn=self.objective_multi,\n",
    "                        space=self.parameter_space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=max_evals,\n",
    "                        trials=trials)\n",
    "        elif self.problem_type == 'regression':\n",
    "            best = fmin(fn=self.objective_regression,\n",
    "                        space=self.parameter_space,\n",
    "                        algo=tpe.suggest,\n",
    "                        max_evals=max_evals,\n",
    "                        trials=trials)\n",
    "        else:\n",
    "            logger.info('Not an acceptable problem type to solve')\n",
    "            return None\n",
    "        return space_eval(self.parameter_space, best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "found-parade",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:45.949757Z",
     "start_time": "2022-02-01T23:58:45.932700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2 id=\"HpOptFeatureSelection\" class=\"doc_header\"><code>class</code> <code>HpOptFeatureSelection</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h2>\n",
       "\n",
       "> <code>HpOptFeatureSelection</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`space`**, **`model`**, **`problem_type`**)\n",
       "\n",
       "Uses hyperopt to remove features while maximizing an objective for a given problem\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptFeatureSelection.__init__\" class=\"doc_header\"><code>HpOptFeatureSelection.__init__</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptFeatureSelection.__init__</code>(**`X_train`**, **`X_test`**, **`y_train`**, **`y_test`**, **`space`**, **`model`**, **`problem_type`**)\n",
       "\n",
       "Initialize data, model, and problem type\n",
       "\n",
       "Args:\n",
       "* X_train (DataFrame): training dataframe of features\n",
       "* X_test (DataFrame): testing dataframe of labels\n",
       "* y_train (DataFrame): training dataframe of features\n",
       "* y_test (DataFrame): testing dataframe of labels\n",
       "* space (dict): dictionary with each feature corresponding to a hyperopt choice object\n",
       "* model (object): model with \"fit\" and \"predict\" functions that are callable\n",
       "* problem_type (str): one of \"binary\", \"regression\", or \"multilabel\""
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptFeatureSelection.objective_binary\" class=\"doc_header\"><code>HpOptFeatureSelection.objective_binary</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptFeatureSelection.objective_binary</code>(**`params`**)\n",
       "\n",
       "binary loss objective that grabs the columns for feature selection. uses AUC metric\n",
       "\n",
       "Args:\n",
       "* params (dict): which columns to use as features\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptFeatureSelection.objective_multi\" class=\"doc_header\"><code>HpOptFeatureSelection.objective_multi</code><a href=\"__main__.py#L42\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptFeatureSelection.objective_multi</code>(**`params`**)\n",
       "\n",
       "multilabel loss objective that grabs the columns for feature selection. uses AUC metric\n",
       "\n",
       "Args:\n",
       "* params (dict): which columns to use as features\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptFeatureSelection.objective_regression\" class=\"doc_header\"><code>HpOptFeatureSelection.objective_regression</code><a href=\"__main__.py#L57\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptFeatureSelection.objective_regression</code>(**`params`**)\n",
       "\n",
       "regression loss objective that grabs the columns for feature selection. uses MSE metric\n",
       "\n",
       "Args:\n",
       "* params (dict): which columns to use as features\n",
       "\n",
       "Returns:\n",
       "* dict: loss and status for hyperopt optimization"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"HpOptFeatureSelection.optimize\" class=\"doc_header\"><code>HpOptFeatureSelection.optimize</code><a href=\"__main__.py#L72\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>HpOptFeatureSelection.optimize</code>(**`max_evals`**=*`20`*)\n",
       "\n",
       "optimizes a feature space for each type of problem\n",
       "\n",
       "Args:\n",
       "* max_evals (int, optional): number of hyperopt evaluations. Defaults to 20.\n",
       "\n",
       "Returns:\n",
       "* object: hyperopt optimized object of parameters which are features"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(HpOptFeatureSelection)\n",
    "show_doc(HpOptFeatureSelection.__init__)\n",
    "show_doc(HpOptFeatureSelection.objective_binary)\n",
    "show_doc(HpOptFeatureSelection.objective_multi)\n",
    "show_doc(HpOptFeatureSelection.objective_regression)\n",
    "show_doc(HpOptFeatureSelection.optimize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "protected-consistency",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:47.806399Z",
     "start_time": "2022-02-01T23:58:45.951534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/10 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.007170 seconds\n",
      "INFO:hyperopt.tpe:TPE using 0 trials\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|██▌                      | 1/10 [00:00<00:02,  4.45trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.008813 seconds\n",
      "INFO:hyperopt.tpe:TPE using 1/1 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|█████                    | 2/10 [00:00<00:01,  4.70trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.007937 seconds\n",
      "INFO:hyperopt.tpe:TPE using 2/2 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████▌                 | 3/10 [00:00<00:01,  4.79trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.014538 seconds\n",
      "INFO:hyperopt.tpe:TPE using 3/3 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|██████████               | 4/10 [00:00<00:01,  5.12trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.008785 seconds\n",
      "INFO:hyperopt.tpe:TPE using 4/4 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████▌            | 5/10 [00:00<00:00,  5.49trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.006144 seconds\n",
      "INFO:hyperopt.tpe:TPE using 5/5 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████          | 6/10 [00:01<00:00,  5.78trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.006808 seconds\n",
      "INFO:hyperopt.tpe:TPE using 6/6 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|█████████████████▌       | 7/10 [00:01<00:00,  6.17trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.006119 seconds\n",
      "INFO:hyperopt.tpe:TPE using 7/7 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████     | 8/10 [00:01<00:00,  6.41trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.010131 seconds\n",
      "INFO:hyperopt.tpe:TPE using 8/8 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|██████████████████████▌  | 9/10 [00:01<00:00,  6.38trial/s, best loss: 0.002062527138515069]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hyperopt.tpe:build_posterior_wrapper took 0.007144 seconds\n",
      "INFO:hyperopt.tpe:TPE using 9/9 trials with best loss 0.002063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████| 10/10 [00:01<00:00,  5.79trial/s, best loss: 0.0018454190186713015]\n",
      "Original number of features 30\n",
      "Final number of features 17\n"
     ]
    }
   ],
   "source": [
    "# prepare Dataset\n",
    "df = datasets.load_breast_cancer()\n",
    "X = pd.DataFrame(df['data'])\n",
    "X.columns = [str(i) for i in range(X.shape[1])]\n",
    "y = df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# create hyperopt space\n",
    "space = {}\n",
    "for col in X.columns:\n",
    "    space[col] = hp.choice(col, [0, 1])\n",
    "    \n",
    "# select features\n",
    "hpobj = HpOptFeatureSelection(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    y_train,\n",
    "    y_test, \n",
    "    space, \n",
    "    RandomForestClassifier(),\n",
    "    problem_type='binary'\n",
    "    )\n",
    "best = hpobj.optimize(max_evals=10)\n",
    "out = [i for i,j in best.items() if j==1]\n",
    "print(f'Original number of features {X.shape[1]}')\n",
    "print(f'Final number of features {len(out)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-wrist",
   "metadata": {},
   "source": [
    "## Model Movement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-texture",
   "metadata": {},
   "source": [
    "### `save_sklearn_object_to_data_lake`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "positive-flooring",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:47.812883Z",
     "start_time": "2022-02-01T23:58:47.808473Z"
    }
   },
   "outputs": [],
   "source": [
    "#export\n",
    "\n",
    "\n",
    "def save_sklearn_object_to_data_lake(model, file_name, path, container, connection_str, overwrite=False):\n",
    "    \"\"\"moves a sklearn object to azure data lake as a pickle file at a given path\n",
    "\n",
    "    Args:\n",
    "    * model (sklearn object): model, pipeline, transformer in sklearn format\n",
    "    * file_name (str): name of file\n",
    "    * path (str): data lake path\n",
    "    * container (str): data lake container\n",
    "    * connection_str (str): azure connection string for the account\n",
    "    * overwrite (bool, optional): set to overwrite a current file if there`. Defaults to False.\n",
    "    \"\"\"\n",
    "    logger.info(f'Pushing Sklearn Object to Azure: {os.path.join(path, file_name)}')\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    blob_pusher(container_name=container,\n",
    "                connection_str=connection_str,\n",
    "                file_path=[file_name],\n",
    "                blob_dest=[path],\n",
    "                overwrite=overwrite)\n",
    "    os.unlink(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "current-chase",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:47.820875Z",
     "start_time": "2022-02-01T23:58:47.814912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"save_sklearn_object_to_data_lake\" class=\"doc_header\"><code>save_sklearn_object_to_data_lake</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>save_sklearn_object_to_data_lake</code>(**`model`**, **`file_name`**, **`path`**, **`container`**, **`connection_str`**, **`overwrite`**=*`False`*)\n",
       "\n",
       "moves a sklearn object to azure data lake as a pickle file at a given path\n",
       "\n",
       "Args:\n",
       "* model (sklearn object): model, pipeline, transformer in sklearn format\n",
       "* file_name (str): name of file\n",
       "* path (str): data lake path\n",
       "* container (str): data lake container\n",
       "* connection_str (str): azure connection string for the account\n",
       "* overwrite (bool, optional): set to overwrite a current file if there`. Defaults to False."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(save_sklearn_object_to_data_lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "knowing-strength",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T23:58:50.161922Z",
     "start_time": "2022-02-01T23:58:47.822260Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pushing Sklearn Object to Azure: sdsde_library/testing/models/RandomForestExample.pickle\n",
      "INFO:sdsde.azure.filehandling:sdsdetesting is a valid\n",
      "INFO:sdsde.azure.filehandling:ContainerAlreadyExists\n",
      "INFO:sdsde.azure.filehandling:Uploading RandomForestExample.pickle, to to Azure Storage sdsde_library/testing/models/RandomForestExample.pickle\n",
      "INFO:sdsde.azure.filehandling:Azure Upload Complete\n"
     ]
    }
   ],
   "source": [
    "#skip\n",
    "save_sklearn_object_to_data_lake(model=model,\n",
    "                                 file_name='RandomForestExample.pickle',\n",
    "                                 path='sdsde_library/testing/models/', \n",
    "                                 container='sdsdetesting', \n",
    "                                 connection_str=os.environ['DATALAKE_CONN_STR_SECRET'], \n",
    "                                 overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "speaking-three",
   "metadata": {},
   "source": [
    "# Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foster-miniature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_azure.ipynb.\n",
      "Converted 02_utils_dataframes.ipynb.\n",
      "Converted 02_utils_fastai_helpers.ipynb.\n",
      "Converted 02_utils_parseyaml.ipynb.\n",
      "Converted 02_utils_stfp.ipynb.\n",
      "Converted 02_utils_traininghelpers.ipynb.\n",
      "Converted 03_dstools_preparedata.ipynb.\n",
      "Converted 04_snowflake_copyinto.ipynb.\n",
      "Converted 04_snowflake_copyinto2.ipynb.\n",
      "Converted 04_snowflake_query.ipynb.\n",
      "Converted 05_azure_wrappers.ipynb.\n",
      "Converted 06_modeling_inference.ipynb.\n",
      "Converted 06_modeling_inference_fastai.ipynb.\n",
      "Converted 06_modeling_premodel.ipynb.\n",
      "Converted 06_modeling_preprocessing.ipynb.\n",
      "Converted 06_modeling_preprocessing_fastai.ipynb.\n",
      "Converted 06_modeling_training.ipynb.\n",
      "Converted 06_modeling_training_fastai.ipynb.\n",
      "Converted 07_Binary_Classification_Fastai_Example_Notebook.ipynb.\n",
      "Converted 08_yaml_ingestion_binary_classification.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f6722b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
